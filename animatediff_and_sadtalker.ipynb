{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import re\n",
    "import os\n",
    "import shutil\n",
    "import requests\n",
    "from diffusers import DiffusionPipeline\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(dotenv_path='.env')\n",
    "\n",
    "def voice_generation(dialogue, gender, output_audio_destination_path):\n",
    "    \"\"\"\n",
    "    Generate voice using the Elevenlabs Text-to-Speech API and save the output audio to a destination path.\n",
    "\n",
    "    Parameters:\n",
    "        dialogue (str): The text to be converted into speech.\n",
    "        gender (str): The gender of the voice (either 'female' or 'male').\n",
    "        output_audio_destination_path (str): The path where the generated audio will be saved.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create Voice using Elevenlabs\n",
    "    CHUNK_SIZE = 1024\n",
    "    id = \"\"\n",
    "    if gender == \"female\":\n",
    "        id = \"21m00Tcm4TlvDq8ikWAM\"\n",
    "    elif gender == \"male\":\n",
    "        id = \"ODq5zmih8GrVes37Dizd\"\n",
    "\n",
    "    url = f\"https://api.elevenlabs.io/v1/text-to-speech/{id}\"\n",
    "\n",
    "    headers = {\n",
    "    \"Accept\": \"audio/mpeg\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"xi-api-key\": os.getenv(\"ELEVENLABS_API_KEY\")\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "    \"text\": dialogue,\n",
    "    \"model_id\": \"eleven_monolingual_v1\",\n",
    "    \"voice_settings\": {\n",
    "        \"stability\": 0.5,\n",
    "        \"similarity_boost\": 0.5\n",
    "    }\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, json=data, headers=headers)\n",
    "    with open('output.mp3', 'wb') as f:\n",
    "        for chunk in response.iter_content(chunk_size=CHUNK_SIZE):\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "\n",
    "    # Copy the generated audio to the unreal engine project\n",
    "    shutil.copy('output.mp3', output_audio_destination_path)\n",
    "\n",
    "\n",
    "def person_generate(prompt, gender, output_path):\n",
    "    \"\"\"\n",
    "    Generate images from text using the DiffusionPipeline model and save the images to the specified output path.\n",
    "\n",
    "    Parameters:\n",
    "        prompt (str): The text prompt for image generation.\n",
    "        gender (str): The gender associated with the prompt ('male' or 'female').\n",
    "        output_path (str): The path where the generated images will be saved.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the DiffusionPipeline model\n",
    "    pipe = DiffusionPipeline.from_pretrained(\"SG161222/RealVisXL_V2.0\", torch_dtype=torch.float16, use_safetensors=True, variant=\"fp16\")\n",
    "    pipe.to(\"cuda\")\n",
    "    if gender == 'male':\n",
    "        prompt_addition = '4k, photorealistic, man, male, portrait, ultra realistic, high quality, face clearly visible, ray tracing, model '\n",
    "    if gender == 'female':\n",
    "        prompt_addition = '4k, photorealistic, woman, female, portrait, ultra realistic, high quality, face clearly visible, ray tracing, model '\n",
    "    promp = prompt_addition + prompt\n",
    "    # Generate images from text\n",
    "    images = pipe(prompt=prompt).images[0]\n",
    "    images.save(output_path)\n",
    "\n",
    "def update_prompt_yaml(output_path, prompt_text):\n",
    "    \"\"\"\n",
    "    Update a YAML configuration file with a new text prompt.\n",
    "\n",
    "    Parameters:\n",
    "        output_path (str): The path to the YAML configuration file to be updated.\n",
    "        prompt_text (str): The new text prompt to be added to the configuration file.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create yaml file\n",
    "    yaml_content = f\"\"\"\\\n",
    "Prompt:\n",
    "  base: \"\"\n",
    "  path: \"models/DreamBooth_LoRA/realisticVisionV51_v20Novae.safetensors\"\n",
    "  motion_module:\n",
    "    - \"models/Motion_Module/mm_sd_v14.ckpt\"\n",
    "    - \"models/Motion_Module/mm_sd_v15.ckpt\"\n",
    "\n",
    "  seed:           5658137986800322009\n",
    "  steps:          25\n",
    "  guidance_scale: 7.5\n",
    "\n",
    "  prompt:\n",
    "    - \"{prompt_text}\"\n",
    "  n_prompt:\n",
    "    - \"semi-realistic, cgi, 3d, render, sketch, cartoon, drawing, anime, text, close up, cropped, out of frame, worst quality, low quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, extra fingers, mutated hands, poorly drawn hands, poorly drawn face, mutation, deformed, blurry, dehydrated, bad anatomy, bad proportions, extra limbs, cloned face, disfigured, gross proportions, malformed limbs, missing arms, missing legs, extra arms, extra legs, fused fingers, too many fingers, long neck\"\n",
    "\"\"\"\n",
    "\n",
    "    # Write the updated content to the output file\n",
    "    with open(output_path, 'w') as file:\n",
    "        file.write(yaml_content)\n",
    "\n",
    "\n",
    "def extract_gender(text):\n",
    "    \"\"\"\n",
    "    Extract and return the gender information from a text string.\n",
    "\n",
    "    Parameters:\n",
    "        text (str): The text containing gender information.\n",
    "\n",
    "    Returns:\n",
    "        str: The extracted gender ('male' or 'female') or None if not found.\n",
    "    \"\"\"\n",
    "\n",
    "    # find gender\n",
    "    gender_match = re.search(r'\\((male|female)\\)', text)\n",
    "    if gender_match:\n",
    "        return gender_match.group(1)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def extract_dialogue(text):\n",
    "    \"\"\"\n",
    "    Extract and return the dialogue from a text string enclosed in '<dialogue>' tags.\n",
    "\n",
    "    Parameters:\n",
    "        text (str): The text containing dialogue enclosed in '<dialogue>' tags.\n",
    "\n",
    "    Returns:\n",
    "        str: The extracted dialogue text or None if not found.\n",
    "    \"\"\"\n",
    "\n",
    "    # find dialogue\n",
    "    dialogue_match = re.search(r'<dialogue>(.*?)<\\/dialogue>', text)\n",
    "    if dialogue_match:\n",
    "        return dialogue_match.group(1)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def handle_animatediff(item):\n",
    "    \"\"\"\n",
    "    Process an 'animatediff' item by updating the prompt YAML file and running a subprocess.\n",
    "\n",
    "    Parameters:\n",
    "        item (dict): A dictionary containing an 'animatediff' item with relevant information.\n",
    "    \"\"\"\n",
    "\n",
    "    # modify prompt value for high quality generations\n",
    "    prompt = item['animatediff'] + \"4k, photo realistic, ultra quality, realistic, beautiful, hyper realistic, ray tracing, reflections.\"\n",
    "    \n",
    "    # Modify the prompt.yaml file\n",
    "    update_prompt_yaml(\"AnimateDiff/configs/prompts/prompt.yaml\", prompt)\n",
    "\n",
    "    # Run the command using subprocess with the \"cd\" command\n",
    "    command = [\"cd\", \"AnimateDiff\", \"&&\", \"conda\", \"activate\", \"animatediff\", \"&&\", \"python\", \"-m\", \"scripts.animate\", \"--config\", \"configs/prompts/Prompt.yaml\"]\n",
    "    \n",
    "    subprocess.run(\" \".join(command), shell=True)\n",
    "\n",
    "def handle_sadtalker(item):\n",
    "    \"\"\"\n",
    "    Process a 'sadtalker' item by generating audio and images and running SadTalker subprocess.\n",
    "\n",
    "    Parameters:\n",
    "        item (dict): A dictionary containing a 'sadtalker' item with relevant information.\n",
    "    \"\"\"\n",
    "\n",
    "    # extract dialogue and gender\n",
    "    dialogue = extract_dialogue(item['sadtalker'])\n",
    "    gender = extract_gender(item['sadtalker'])\n",
    "\n",
    "    if dialogue and gender:\n",
    "        # Set paths for audio and image\n",
    "        audio_path = \"SadTalker/examples/driven_audio/audio.wav\"\n",
    "        image_path = \"SadTalker/examples/source_image/image.png\"\n",
    "        output_path = \"SadTalker/examples/results\"\n",
    "\n",
    "        # Generate audio\n",
    "        voice_generation(dialogue, gender, audio_path)\n",
    "\n",
    "        # Generate image\n",
    "        person_generate(item['sadtalker'], gender, image_path)\n",
    "\n",
    "        # Run SadTalker subprocess\n",
    "        command = [\"SadTalker/venv/scripts/python.exe\", \"SadTalker/inference.py\",\n",
    "                   \"--driven_audio\", audio_path, \"--source_image\", image_path,\n",
    "                   \"--result_dir\", output_path, \"--still\", \"--preprocess\", \"full\", \"--enhancer\", \"gfpgan\"]\n",
    "        subprocess.run(command)\n",
    "\n",
    "def process_formatted_llm_lines(formatted_llm_lines):\n",
    "    \"\"\"\n",
    "    Process a list of formatted LLM lines, handling both 'animatediff' and 'sadtalker' items.\n",
    "\n",
    "    Parameters:\n",
    "        formatted_llm_lines (list): A list of dictionaries containing formatted LLM items.\n",
    "    \"\"\"\n",
    "\n",
    "    # iterate through the lines\n",
    "    for item in formatted_llm_lines:\n",
    "        if 'animatediff' in item:\n",
    "            handle_animatediff(item)\n",
    "        elif 'sadtalker' in item:\n",
    "            handle_sadtalker(item)\n",
    "\n",
    "\n",
    "formatted_llm_lines = [{'animatediff': 'Imagine a dark and gritty street in the heart of a city, the sounds of traffic and people bustling by. The scene is lit by the neon lights of nearby businesses., car, person, traffic light'},\n",
    " {'sadtalker': 'John Wick, a legendary assassin, stands in the middle of the street, his eyes cold and his face impassive. He is wearing a black suit and holding a gun in his hand. He says, <dialogue>\"I\\'m going to kill them all\"</dialogue> (male)., person, car, tie, umbrella'},\n",
    " {'animatediff': 'John Wick is a deadly assassin, known for his prowess in taking down his targets with precision and efficiency. He is a man on a mission, and he will stop at nothing to get what he wants. With his gun at the ready, he stalks the streets, searching for his next target., person, cell phone, tie'}]\n",
    "\n",
    "process_formatted_llm_lines(formatted_llm_lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
